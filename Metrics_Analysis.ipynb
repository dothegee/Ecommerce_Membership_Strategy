{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler \n",
    "from pyspark.sql import SparkSession \n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DateType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import col, array_contains, isnan, when, count\n",
    "from pyspark.sql.functions import lit, concat_ws, concat, collect_list, udf\n",
    "from pyspark.sql.functions import countDistinct\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark 접속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faulthandler.enable()   \n",
    "spark = SparkSession.builder.master('local').appName(\"Python Spark SQL Practice\").config(\"spark.driver.maxResultSize\", \"64g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    file_list = []\n",
    "    for filename in filenames:\n",
    "        full_filename = os.path.join(dirname, filename)\n",
    "        print(full_filename)\n",
    "        file_list.append(full_filename)\n",
    "    return file_list\n",
    "data_path_list = search(\"D:/workspace/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스키마 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType() \\\n",
    "      .add(\"event_time\",TimestampType(),True) \\\n",
    "      .add(\"event_type\",StringType(),True) \\\n",
    "      .add(\"product_id\",StringType(),True) \\\n",
    "      .add(\"category_id\",StringType(),True) \\\n",
    "      .add(\"category_code\",StringType(),True) \\\n",
    "      .add(\"brand\",StringType(),True) \\\n",
    "      .add(\"price\",DoubleType(),True) \\\n",
    "      .add(\"user_id\",StringType(),True) \\\n",
    "      .add(\"user_session\",StringType(),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data merge\n",
    "    - 2019년 10월 ~ 2020년 4월"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(data_path_list):\n",
    "    file_path = x\n",
    "    df = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .option('delimiter', ',') \\\n",
    "      .schema(schema) \\\n",
    "      .load(file_path)\n",
    "    if i == 0:\n",
    "        merged_df = df\n",
    "    else:\n",
    "        merged_df = merged_df.union(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark table 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.createOrReplaceTempView(\"ecommerce\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
